{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library and api key import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does this function do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will this function retrieves all\n",
    "#the comments inside the first x videos that appear on youtube, for a particular string. It will include comment\n",
    "# replies for each comment. Likely delivering a bigger quantity of results that getcomments_for_multiple_videos_no_replies\n",
    "# but with  a cost, it will increase a LOT execution time. We recommend executing this for a small number of videos\n",
    "# maxing 10. \n",
    "\n",
    "videolist = []\n",
    "totallist = []\n",
    "commentthreadlist = []\n",
    "\n",
    "# THis are three key elements, used for us to store the results of our code , we created them on the outside of the functions\n",
    "# because the processes that will happen on this code can be really extensive, to the point where we separated the\n",
    "# code in three parts. TO make sure the variables all always there , we created the variables globally. \n",
    "#The first part declares a function that obtains comment responses for a particular comment thread\n",
    "# the second part will create a function that obtains comments for a particular video id. The third part gets the list\n",
    "# of videos for the string we give, and executed the function for comment gathering in a loop, delivering all of them in\n",
    "# a dataframe. To understand the code inside , we recommend reading the 'individual youtube api functions' , there \n",
    "# we use very similar functions independently and explain the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library and api key import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing api key, and calling the libraries to be used\n",
    "import json\n",
    "\n",
    "with open('youtube_credentials.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "    api_key = info[\"youtube_apikeyjson\"]\n",
    "\n",
    "\n",
    "# Here we import library, and create a youtube object that will represent our conection to the api, through which we\n",
    "# will perform our requests\n",
    "from apiclient.discovery import build\n",
    "youtube = build('youtube' , 'v3' , developerKey= api_key)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# THis are two key elements, used for us to store the results of our code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get comment responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcommentresponses(commentid, objectpart = \"snippet\" , resultnumber = 100 , textFormat = \"plainText\"  ):\n",
    "    callobject = youtube.commentThreads().list(part = objectpart , maxResults = resultnumber, \n",
    "                                               textFormat = \"plainText\" , id = commentid)\n",
    "    results = callobject.execute()\n",
    "    \n",
    "    for item in results[\"items\"]:\n",
    "            \n",
    "        comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "        author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "        text = comment[\"snippet\"][\"textDisplay\"]\n",
    "        resultdic = {\"user\" : author ,\"usercomment\" : comment[\"snippet\"][\"textDisplay\"], \n",
    "                   \"likecount\" : comment[\"snippet\"][\"likeCount\"], \"commentid\" : item[\"id\"], \n",
    "                     \"publishingdate\" : comment[\"snippet\"][\"publishedAt\"]}\n",
    "                \n",
    "        totallist.append(resultdic)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get comment threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is the function used to retrieve comments for a particular video id.  We separate it so the get comments for a keyword code\n",
    "# is not so long, and it can be easily modified afterwards.\n",
    "\n",
    "def commentsearch(videoIdentification, partofcomment = \"snippet\", numbrofresult = 100):\n",
    "    callobject = youtube.commentThreads().list(part = partofcomment, videoId = videoIdentification, maxResults = numbrofresult, \n",
    "                                               textFormat = \"plainText\")\n",
    "\n",
    "    results = callobject.execute()\n",
    "    \n",
    "    \n",
    "    # here we are creating a function for extracting all the interesting information of a comment, we will be calling\n",
    "    # it  a lot later. The functions first creates a number of variables with the key elements extracted from\n",
    "    # each interaction of the result object, afterwards, creates a dictionary with those results and adds it to the\n",
    "    #totallist, a list with all comments for the keyword, all of them, from all the videos.  This function\n",
    "    # also creates a list of the comments ids, that will be vital for afterwards, extracting the replies if we want them\n",
    "    \n",
    "    def incosearch() :\n",
    "        for item in results[\"items\"]:\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "            author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "            text = comment[\"snippet\"][\"textDisplay\"]\n",
    "            resultdic = {\"user\" : author ,\"usercomment\" : comment[\"snippet\"][\"textDisplay\"], \n",
    "                   \"likecount\" : comment[\"snippet\"][\"likeCount\"], \"commentid\" : item[\"id\"] ,\n",
    "                     \"publishingdate\" : comment[\"snippet\"][\"publishedAt\"] }\n",
    "            totallist.append(resultdic)\n",
    "            commentthreadlist.append(resultdic[\"commentid\"])\n",
    "            \n",
    "    incosearch() # this is a first call, without it, the first page will get skipped. \n",
    "\n",
    "        \n",
    "    if (\"nextPageToken\" in results) == True : \n",
    "        while (\"nextPageToken\" in results) == True :\n",
    "            callobject = youtube.commentThreads().list(part = partofcomment, videoId = videoIdentification, maxResults = numbrofresult, \n",
    "                                               textFormat = \"plainText\", pageToken = results[\"nextPageToken\"])\n",
    "            results = callobject.execute()\n",
    "            \n",
    "            incosearch() # this will cll incosearch()\n",
    "            \n",
    "      \n",
    "    \n",
    "    elif (\"nextPageToken\" in results) == False :\n",
    "        pass\n",
    "    \n",
    "    print(\"everything ok thus far\")\n",
    "    print(str(len(commentthreadlist)) + \" are the number of comment threads, replies not included\")\n",
    "    \n",
    "    # Here we get the comment replies , we added to this function in this one, because without it. There would be \n",
    "    # No correct execution on the last call \n",
    "    \n",
    "    for i2 in commentthreadlist:\n",
    "            getcommentresponses(i2)\n",
    "    print(str(len(totallist)) + \" are the number of comments extracted on this video, replies included.\")\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get comments for multiple videos, for a particular string with replies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything ok thus far\n",
      "3794 are the number of comment threads, replies not included\n",
      "7588 are the number of comments extracted on this video, replies included.\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def getcmultividswithR(stringquery, numresults = 25 ,\n",
    "              beforepublished = None , afterpublished = None , rcode = None):\n",
    "    videolist = []\n",
    "    totallist = []\n",
    "    \n",
    "    # Here we call the youtube library, and create a youtube object that represents our conection with the api. \n",
    "    from apiclient.discovery import build\n",
    "    \n",
    "    youtube = build('youtube' , 'v3' , developerKey= api_key)\n",
    "    \n",
    "    \n",
    "    #this function gets a list with videoids for a query, the stringquery we give. If we specify an rcode argument\n",
    "    # or a date before or after publish, this will affect the list of videos obtained. The maximum numbers of videos we \n",
    "    # can obtain are 50. \n",
    "    \n",
    "    funcall = youtube.search().list( q = stringquery ,part = \"id\", type = 'video', maxResults = numresults , \n",
    "                             publishedBefore = beforepublished , publishedAfter = afterpublished, regionCode = rcode ) \n",
    "    result = funcall.execute()\n",
    "    \n",
    "    # after this,collect all the comments from the videos with a loop, using the commentsearchfunction that we have\n",
    "    # created earlier in this document. \n",
    "    \n",
    "\n",
    "    for videoitem in range(0,len(result[\"items\"])):\n",
    "        videoitemid = result[\"items\"][videoitem][\"id\"][\"videoId\"]\n",
    "        videolist.append(videoitemid)\n",
    "        \n",
    "    \n",
    "    for i in videolist:\n",
    "        commentthreadlist = []\n",
    "        commentsearch(videoIdentification = i )\n",
    "        \n",
    "    \n",
    "    finalr = pd.DataFrame(totallist)\n",
    "    \n",
    "            \n",
    "    print(len(totallist))\n",
    "    return(finalr)\n",
    "\n",
    "    \n",
    "    \n",
    "getcmultividswithR(\"potato\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
